{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ba60c74-31c4-4f18-af69-bf5a65d90aa1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "\n",
    "import acquire_b\n",
    "from prepare_b import prep_titanic_data\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0aa04f8-b87d-4ba8-94f2-dde5b4db07b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((498, 9), (214, 9), (179, 9))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Acquire Step\n",
    "df = acquire_b.get_titanic_data()\n",
    "# prepare the data\n",
    "train, validate, test = prep_titanic_data(df)\n",
    "\n",
    "# drop object columns and create X_train of features only \n",
    "# and y_train of survived only. \n",
    "X_train = train.drop(columns=['survived'])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=['survived'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived'])\n",
    "y_test = test.survived\n",
    "\n",
    "# check the shape\n",
    "X_train.shape, X_validate.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba72de30-6cb2-4bc3-94e2-a741ee5e030f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "baseline_prediction = y_train.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b08fd65f-b8a5-426a-81f7-37060429065e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "493    0\n",
       "494    0\n",
       "495    0\n",
       "496    0\n",
       "497    0\n",
       "Length: 498, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series((baseline_prediction[0]), range(len(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab1f405d-f1b0-4114-a6dc-1145ef35724f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# write a function to compute the baseline for a classification model\n",
    "\n",
    "def establish_baseline(y_train):\n",
    "    #  establish the value we will predict for all observations\n",
    "    baseline_prediction = y_train.mode()\n",
    "\n",
    "    # create a series of predictions with that value, \n",
    "    # the same length as our training set\n",
    "    y_train_pred = pd.Series((baseline_prediction[0]), range(len(y_train)))\n",
    "\n",
    "    # compute accuracy of baseline\n",
    "    cm = confusion_matrix(y_train, y_train_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    accuracy = (tp+tn)/(tn+fp+fn+tp)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19b0e562-6b5e-4203-80ff-8452dad85edd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6164658634538153"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "establish_baseline(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461610ed-507a-49ff-af14-3c7d7f607eb6",
   "metadata": {},
   "source": [
    "1. Fit a K-Nearest Neighbors classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77d6ecbb-7446-4165-92ff-e0095d4373e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MAKE the thing\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# FIT the thing\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# USE the thing\n",
    "y_train_pred = knn.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c37a37a-5fbb-4e4b-b268-ba273d32e24f",
   "metadata": {},
   "source": [
    "2. Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46d584d8-c23a-46f5-b5b0-406dd30e095d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7951807228915663"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the accuracy score of train set\n",
    "train_score = knn.score(X_train, y_train)\n",
    "train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d93d043-3dfd-4b27-b7f8-bbd479e8b1b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred 0</th>\n",
       "      <th>Pred 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>258</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>53</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pred 0  Pred 1\n",
       "Actual 0     258      49\n",
       "Actual 1      53     138"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix\n",
    "cm = confusion_matrix(y_train, y_train_pred)\n",
    "pd.DataFrame(cm, index=['Actual 0', 'Actual 1'], \n",
    "             columns=['Pred 0', 'Pred 1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cec7ab6-4cfb-4ab8-87e4-b11690aaf9d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.83       307\n",
      "           1       0.74      0.72      0.73       191\n",
      "\n",
      "    accuracy                           0.80       498\n",
      "   macro avg       0.78      0.78      0.78       498\n",
      "weighted avg       0.79      0.80      0.79       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2eb53080-1f3b-45c4-83cc-06a9d59c1b93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.829582</td>\n",
       "      <td>0.840391</td>\n",
       "      <td>0.834951</td>\n",
       "      <td>307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.737968</td>\n",
       "      <td>0.722513</td>\n",
       "      <td>0.730159</td>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.795181</td>\n",
       "      <td>0.795181</td>\n",
       "      <td>0.795181</td>\n",
       "      <td>0.795181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.783775</td>\n",
       "      <td>0.781452</td>\n",
       "      <td>0.782555</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.794445</td>\n",
       "      <td>0.795181</td>\n",
       "      <td>0.794760</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              0.829582  0.840391  0.834951  307.000000\n",
       "1              0.737968  0.722513  0.730159  191.000000\n",
       "accuracy       0.795181  0.795181  0.795181    0.795181\n",
       "macro avg      0.783775  0.781452  0.782555  498.000000\n",
       "weighted avg   0.794445  0.795181  0.794760  498.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#classification report as a df\n",
    "pd.DataFrame(classification_report(y_train, \n",
    "                                   y_train_pred, \n",
    "                                   output_dict=True)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558915d3-d2f1-45f8-a29f-0512daf8d953",
   "metadata": {},
   "source": [
    "3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29ad2ab1-05ca-488b-9934-a56efd4881ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.795181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>true_positive_rate</td>\n",
       "      <td>0.722513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>false_positive_rate</td>\n",
       "      <td>0.159609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>true_negative_rate</td>\n",
       "      <td>0.840391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>false_negative_rate</td>\n",
       "      <td>0.277487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.737968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.722513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>f1_score</td>\n",
       "      <td>0.730159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>support_pos</td>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>support_neg</td>\n",
       "      <td>307.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                metric       score\n",
       "0             accuracy    0.795181\n",
       "1   true_positive_rate    0.722513\n",
       "2  false_positive_rate    0.159609\n",
       "3   true_negative_rate    0.840391\n",
       "4  false_negative_rate    0.277487\n",
       "5            precision    0.737968\n",
       "6               recall    0.722513\n",
       "7             f1_score    0.730159\n",
       "8          support_pos  191.000000\n",
       "9          support_neg  307.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "accuracy = (tp + tn)/(tn + fp + fn + tp)\n",
    "\n",
    "true_positive_rate = tp/(tp + fn)\n",
    "false_positive_rate = fp/(fp + tn)\n",
    "true_negative_rate = tn/(tn + fp)\n",
    "false_negative_rate = fn/(fn + tp)\n",
    "\n",
    "precision = tp/(tp + fp)\n",
    "recall = tp/(tp + fn)\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "\n",
    "support_pos = tp + fn\n",
    "support_neg = fp + tn\n",
    "\n",
    "dict = {\n",
    "    'metric' : ['accuracy'\n",
    "                ,'true_positive_rate'\n",
    "                ,'false_positive_rate'\n",
    "                ,'true_negative_rate'\n",
    "                ,'false_negative_rate'\n",
    "                ,'precision'\n",
    "                ,'recall'\n",
    "                ,'f1_score'\n",
    "                ,'support_pos'\n",
    "                ,'support_neg']\n",
    "    ,'score' : [accuracy\n",
    "                ,true_positive_rate\n",
    "                ,false_positive_rate\n",
    "                ,true_negative_rate\n",
    "                ,false_negative_rate\n",
    "                ,precision\n",
    "                ,recall\n",
    "                ,f1_score\n",
    "                ,support_pos\n",
    "                ,support_neg]\n",
    "}\n",
    "\n",
    "pd.DataFrame(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3ecddf6-b30c-4be1-9117-560b24a0d615",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_cm_metrics(cm):\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    accuracy = (tp + tn)/(tn + fp + fn + tp)\n",
    "\n",
    "    true_positive_rate = tp/(tp + fn)\n",
    "    false_positive_rate = fp/(fp + tn)\n",
    "    true_negative_rate = tn/(tn + fp)\n",
    "    false_negative_rate = fn/(fn + tp)\n",
    "\n",
    "    precision = tp/(tp + fp)\n",
    "    recall = tp/(tp + fn)\n",
    "    f1_score = 2*(precision*recall)/(precision+recall)\n",
    "\n",
    "    support_pos = tp + fn\n",
    "    support_neg = fp + tn\n",
    "\n",
    "    dict = {\n",
    "        'metric' : ['accuracy'\n",
    "                    ,'true_positive_rate'\n",
    "                    ,'false_positive_rate'\n",
    "                    ,'true_negative_rate'\n",
    "                    ,'false_negative_rate'\n",
    "                    ,'precision'\n",
    "                    ,'recall'\n",
    "                    ,'f1_score'\n",
    "                    ,'support_pos'\n",
    "                    ,'support_neg']\n",
    "        ,'score' : [accuracy\n",
    "                    ,true_positive_rate\n",
    "                    ,false_positive_rate\n",
    "                    ,true_negative_rate\n",
    "                    ,false_negative_rate\n",
    "                    ,precision\n",
    "                    ,recall\n",
    "                    ,f1_score\n",
    "                    ,support_pos\n",
    "                    ,support_neg]\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame(dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806fdf4f-ff4c-439e-8bfa-93b18c1c868e",
   "metadata": {},
   "source": [
    "4. Run through steps 1-3 setting k to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3ce4365-1907-4dae-bc0e-a2c6b7123032",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Let's create a function to make, fit and use the model\n",
    "\n",
    "def knn_fit_predict(k, X_train, y_train, X_validate):\n",
    "    '''\n",
    "    This function takes n_neighbors, X_train,  target  and X_val\n",
    "    and returns knn, predictions for train set and validate set\n",
    "    '''\n",
    "    # MAKE the thing\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    # FIT the thing\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # USE the thing\n",
    "    y_train_pred = knn.predict(X_train)\n",
    "    y_validate_pred = knn.predict(X_validate)\n",
    "    \n",
    "    return knn, y_train_pred, y_validate_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05343deb-d76e-4656-82ef-5e83ca6a406f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Now, let's make a function to return the \n",
    "#accuracy, confusion matrix and classification report\n",
    "\n",
    "def evaluate_clf(model, X, y, y_pred):\n",
    "    '''\n",
    "    This function can be used on any classification model\n",
    "    It takes in a model, features, target and prediction\n",
    "    and returns the accuracy, confusion matrix and classification report\n",
    "    '''\n",
    "    # model score\n",
    "    accuracy = model.score(X, y)\n",
    "\n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    cmdf = pd.DataFrame(cm, index=['Actual 0', 'Actual 1'], \n",
    "                       columns=['Pred 0', 'Pred 1'])\n",
    "\n",
    "    # classification report\n",
    "    crdf = pd.DataFrame(classification_report(y, y_pred, output_dict=True))\n",
    "    \n",
    "    # confusion matrix metrics\n",
    "    metrics = print_cm_metrics(cm)\n",
    "    \n",
    "    return accuracy, cmdf, crdf, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca2e44ea-1694-4cec-928d-798dd3ad8c25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#using the functions we created above, and store what's returned in variables:\n",
    "k = 10\n",
    "knn, y_train_pred, y_validate_pred = knn_fit_predict(k, \n",
    "                                                     X_train, \n",
    "                                                     y_train, \n",
    "                                                     X_validate)\n",
    "accuracy_t, cmdf_t, crdf_t, metrics_t = evaluate_clf(knn, X_train, y_train, y_train_pred)\n",
    "\n",
    "accuracy_v, cmdf_v, crdf_v, metrics_v = evaluate_clf(knn, X_validate, y_validate, y_validate_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f85ab814-fbbc-4e1f-8851-62925982d19b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN where K = 10\n",
      "\n",
      "********Train Evaluation********\n",
      "\n",
      "Accuracy: 0.7449799196787149\n",
      "\n",
      "Confusion Matrix:\n",
      "          Pred 0  Pred 1\n",
      "Actual 0     275      32\n",
      "Actual 1      95      96\n",
      "\n",
      "Classification Report:\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.743243    0.750000   0.74498    0.746622      0.745835\n",
      "recall       0.895765    0.502618   0.74498    0.699192      0.744980\n",
      "f1-score     0.812408    0.601881   0.74498    0.707144      0.731663\n",
      "support    307.000000  191.000000   0.74498  498.000000    498.000000\n",
      "\n",
      "Metrics: \n",
      "                metric       score\n",
      "0             accuracy    0.744980\n",
      "1   true_positive_rate    0.502618\n",
      "2  false_positive_rate    0.104235\n",
      "3   true_negative_rate    0.895765\n",
      "4  false_negative_rate    0.497382\n",
      "5            precision    0.750000\n",
      "6               recall    0.502618\n",
      "7             f1_score    0.601881\n",
      "8          support_pos  191.000000\n",
      "9          support_neg  307.000000\n",
      " \n",
      "________________________________________________\n",
      "\n",
      "********Validate Evaluation********\n",
      "\n",
      "Accuracy: 0.7242990654205608\n",
      "\n",
      "Confusion Matrix:\n",
      "          Pred 0  Pred 1\n",
      "Actual 0     115      17\n",
      "Actual 1      42      40\n",
      "\n",
      "Classification Report:\n",
      "                    0          1  accuracy   macro avg  weighted avg\n",
      "precision    0.732484   0.701754  0.724299    0.717119      0.720709\n",
      "recall       0.871212   0.487805  0.724299    0.679508      0.724299\n",
      "f1-score     0.795848   0.575540  0.724299    0.685694      0.711431\n",
      "support    132.000000  82.000000  0.724299  214.000000    214.000000\n",
      "\n",
      "Metrics: \n",
      "                metric       score\n",
      "0             accuracy    0.724299\n",
      "1   true_positive_rate    0.487805\n",
      "2  false_positive_rate    0.128788\n",
      "3   true_negative_rate    0.871212\n",
      "4  false_negative_rate    0.512195\n",
      "5            precision    0.701754\n",
      "6               recall    0.487805\n",
      "7             f1_score    0.575540\n",
      "8          support_pos   82.000000\n",
      "9          support_neg  132.000000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"KNN where K = {k}\n",
    "\n",
    "********Train Evaluation********\n",
    "\n",
    "Accuracy: {accuracy_t}\n",
    "\n",
    "Confusion Matrix:\n",
    "{cmdf_t}\n",
    "\n",
    "Classification Report:\n",
    "{crdf_t}\n",
    "\n",
    "Metrics: \n",
    "{metrics_t}\n",
    " \n",
    "________________________________________________\n",
    "\n",
    "********Validate Evaluation********\n",
    "\n",
    "Accuracy: {accuracy_v}\n",
    "\n",
    "Confusion Matrix:\n",
    "{cmdf_v}\n",
    "\n",
    "Classification Report:\n",
    "{crdf_v}\n",
    "\n",
    "Metrics: \n",
    "{metrics_v}\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e25b4d-fb27-4250-ab77-78f8156bfbdc",
   "metadata": {},
   "source": [
    "5. Run through steps 1-3 setting k to 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cfd05b22-1255-45af-ab23-31356197b8ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "k = 20\n",
    "knn, y_train_pred, y_validate_pred = knn_fit_predict(k, \n",
    "                                                     X_train, \n",
    "                                                     y_train, \n",
    "                                                     X_validate)\n",
    "accuracy_t, cmdf_t, crdf_t, met_t = evaluate_clf(knn, X_train, y_train, y_train_pred)\n",
    "\n",
    "accuracy_v, cmdf_v, crdf_v, met_v = evaluate_clf(knn, X_validate, y_validate, y_validate_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a2ed1b4-be91-4c5f-aafa-6a6bbf3ea53f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN where K = 20\n",
      "\n",
      "********Train Evaluation********\n",
      "\n",
      "Accuracy: 0.7188755020080321\n",
      "\n",
      "Confusion Matrix:\n",
      "          Pred 0  Pred 1\n",
      "Actual 0     269      38\n",
      "Actual 1     102      89\n",
      "\n",
      "Classification Report:\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.725067    0.700787  0.718876    0.712927      0.715755\n",
      "recall       0.876221    0.465969  0.718876    0.671095      0.718876\n",
      "f1-score     0.793510    0.559748  0.718876    0.676629      0.703855\n",
      "support    307.000000  191.000000  0.718876  498.000000    498.000000\n",
      "\n",
      "Metrics: \n",
      "                metric       score\n",
      "0             accuracy    0.718876\n",
      "1   true_positive_rate    0.465969\n",
      "2  false_positive_rate    0.123779\n",
      "3   true_negative_rate    0.876221\n",
      "4  false_negative_rate    0.534031\n",
      "5            precision    0.700787\n",
      "6               recall    0.465969\n",
      "7             f1_score    0.559748\n",
      "8          support_pos  191.000000\n",
      "9          support_neg  307.000000\n",
      " \n",
      "________________________________________________\n",
      "\n",
      "********Validate Evaluation********\n",
      "\n",
      "Accuracy: 0.7149532710280374\n",
      "\n",
      "Confusion Matrix:\n",
      "          Pred 0  Pred 1\n",
      "Actual 0     112      20\n",
      "Actual 1      41      41\n",
      "\n",
      "Classification Report:\n",
      "                    0          1  accuracy   macro avg  weighted avg\n",
      "precision    0.732026   0.672131  0.714953    0.702079      0.709076\n",
      "recall       0.848485   0.500000  0.714953    0.674242      0.714953\n",
      "f1-score     0.785965   0.573427  0.714953    0.679696      0.704525\n",
      "support    132.000000  82.000000  0.714953  214.000000    214.000000\n",
      "\n",
      "Metrics: \n",
      "                metric       score\n",
      "0             accuracy    0.714953\n",
      "1   true_positive_rate    0.500000\n",
      "2  false_positive_rate    0.151515\n",
      "3   true_negative_rate    0.848485\n",
      "4  false_negative_rate    0.500000\n",
      "5            precision    0.672131\n",
      "6               recall    0.500000\n",
      "7             f1_score    0.573427\n",
      "8          support_pos   82.000000\n",
      "9          support_neg  132.000000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"KNN where K = {k}\n",
    "\n",
    "********Train Evaluation********\n",
    "\n",
    "Accuracy: {accuracy_t}\n",
    "\n",
    "Confusion Matrix:\n",
    "{cmdf_t}\n",
    "\n",
    "Classification Report:\n",
    "{crdf_t}\n",
    "\n",
    "Metrics: \n",
    "{met_t}\n",
    " \n",
    "________________________________________________\n",
    "\n",
    "********Validate Evaluation********\n",
    "\n",
    "Accuracy: {accuracy_v}\n",
    "\n",
    "Confusion Matrix:\n",
    "{cmdf_v}\n",
    "\n",
    "Classification Report:\n",
    "{crdf_v}\n",
    "\n",
    "Metrics: \n",
    "{met_v}\n",
    "\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
